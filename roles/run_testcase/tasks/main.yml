---
- name:                  "Set ansible facts"
  import_tasks:          vars/set_facts/set_facts_for_testcase.yml
# Write header for logfile
- name: "Test {{ TESTCASE }} start: {{ DESCRIPTION }}"
  ansible.builtin.lineinfile:
    path: "{{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}.csv"
    line: "{{ ansible_hostname }},{{ SCENARIO }},{{ TESTCASE }},{{ lookup('pipe', 'date +%Y-%m-%dT%H:%M:%S') }}"
- name: "Start sadc data gathering for {{ TESTCASE }}"
  become: yes
  become_user: root
  become_method: sudo
  async: 86400
  poll: 0
  ansible.builtin.shell: |
    {{ SADC_BIN_PATH }}/sadc 60 -L -S POWER -S XDISK {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data
  register: sar_data_gathering
- name: "Stop all chia processes"
  ignore_errors: yes
  ansible.builtin.shell: |
    . {{ CHIA_SW_PATH }}/activate && chia stop all -d
- name: "Remove old sqlite db files (including shm + wal + journal)"
  ansible.builtin.file:
    path: "{{ item }}"
    state: absent
  with_items:
    - "{{ BLOCKCHAIN_DB_PATH }}/{{ BLOCKCHAIN_DB_NAME }}"
    - "{{ BLOCKCHAIN_DB_PATH }}/{{ BLOCKCHAIN_DB_NAME }}-shm"
    - "{{ BLOCKCHAIN_DB_PATH }}/{{ BLOCKCHAIN_DB_NAME }}-wal"
    - "{{ BLOCKCHAIN_DB_PATH }}/{{ BLOCKCHAIN_DB_NAME }}-journal"
- name: "Copy extracted sqlite db file {{ DB_BACKUP }} to {{ BLOCKCHAIN_DB_NAME }}"
  when: SCENARIO != 'FULLSYNC'
  ansible.builtin.command: "cp {{ BLOCKCHAIN_DB_PATH }}/{{ DB_BACKUP }} {{ BLOCKCHAIN_DB_PATH }}/{{ BLOCKCHAIN_DB_NAME }}"
- name: "Change page_size if CHANGE_PAGE_SIZE is true"
  when: CHANGE_PAGE_SIZE
  ansible.builtin.import_role:
    name: change_sqlite_page_size
- name: "Setup chia using branch for given testcase"
  include_role:
    name: setup_chia
- name: "Clear FS Caches to get comparable runtimes"
  become: yes
  become_user: root
  become_method: sudo
  ansible.builtin.shell: |
    sync; echo 1 > /proc/sys/vm/drop_caches
- name: "Write Log: {{ TESTCASE }} initiate sync"
  ansible.builtin.lineinfile:
    path: "{{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}.csv"
    regexp: "^({{ ansible_hostname }},{{ SCENARIO }},{{ TESTCASE }}.*)$"
    line: "\\1,{{ lookup('pipe', 'date +%Y-%m-%dT%H:%M:%S') }}"
    backrefs: yes
- name: "Start chia full node"
  ansible.builtin.shell: |
    . {{ CHIA_SW_PATH }}/activate && chia start node
- name: "Create hard link to chia logfile"
  ansible.builtin.file:
    src: "{{ OS_USER_HOME }}/.chia/mainnet/log/debug.log"
    dest: "{{ ANSIBLE_LOG_CHIA_PATH }}/{{ CHIA_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.log"
    state: hard
- name: "Tail chia logfile to prevent trigger wait_for for old log entries"
  ansible.builtin.shell: |
    tail -n 1 {{ ANSIBLE_LOG_CHIA_PATH }}/{{ CHIA_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.log
  register: tail_debug_log
- name: "Set fact for tail"
  ansible.builtin.set_fact:
    debug_log_since_test_start: "{{ tail_debug_log.stdout }}"
# Use long timeout so even on slow machines like RPi missing indexes can be created
- name: "Wait for chia node on port 8444"
  ansible.builtin.wait_for:
    port: 8444
    delay: 15
    timeout: 1800
    state: started
- name: "Actively connect to random peers until a minimum of 15 connections is reached"
  async: 86400
  poll: 0
  ansible.builtin.shell: |
    . {{ CHIA_SW_PATH }}/activate
    # get peak from sync_start
    PEAK=`chia show -s|grep "Current Blockchain Status" | awk -F '[/.(]' '{print $2}'`
    # Run as long as the sadc process is active
    while [[ `ps -eo pid,cmd | grep {{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.[s]a.data | wc -l` -ne 0 ]]
    do
      # Actively connect to peers until 15 peers with height >= the peak we are syncing to are reached
      while [[ `chia show -c | grep "-Height:" | awk -v IS_PEAK="$PEAK" '$11 >= IS_PEAK {print "count_me"}' | wc -l` -lt 15 ]] && [[ `ps -eo pid,cmd | grep {{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.[s]a.data | wc -l` -ne 0 ]]
      do
        dig +short a dns-introducer.chia.net @one.one.one.one | head -15 | xargs -i chia show -a \{}:8444
      done
      sleep 60
    done
- name: "Sync until Height {{ SYNC_START_HEIGHT }} is reached"
  ansible.builtin.wait_for:
    path: "{{ ANSIBLE_LOG_CHIA_PATH }}/{{ CHIA_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.log"
    search_regex: "{{ debug_log_since_test_start }}\r(.*\r)*.*Added blocks {{ SYNC_START_HEIGHT }}.* to .*"
    timeout: 86400
- name: "Write Log: {{ TESTCASE }} start sync"
  ansible.builtin.lineinfile:
    path: "{{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}.csv"
    regexp: "^({{ ansible_hostname }},{{ SCENARIO }},{{ TESTCASE }}.*)$"
    line: "\\1,{{ lookup('pipe', 'date +%Y-%m-%dT%H:%M:%S') }}"
    backrefs: yes
- name: "Get height for long sync (wait until reasonable peak is returned)"
  ansible.builtin.shell: |
    while [[ `chia show -s|grep "Current Blockchain Status" | awk -F '[/.(]' '{print $2}'` -lt 1000000 ]]
    do
      sleep 10
    done
    echo $(echo $(echo $(chia show -s|grep "Current Blockchain Status" | awk -F '[/.(]' '{print $2}')-400 | bc)/32|bc)*32|bc
  register: long_sync_peak
  when: SCENARIO == 'FULLSYNC'
- name: "Set facts if Scenario is FULLSYNC"
  ansible.builtin.set_fact:
    DUST_STOP_HEIGHT: "{{ long_sync_peak.stdout }}"
  when: SCENARIO == 'FULLSYNC'
- name: "Sync until Height {{ DUST_START_HEIGHT }} is reached"
  ansible.builtin.wait_for:
    path: "{{ ANSIBLE_LOG_CHIA_PATH }}/{{ CHIA_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.log"
    search_regex: "{{ debug_log_since_test_start }}\r(.*\r)*.*Added blocks .* to {{ DUST_START_HEIGHT }}.*"
    timeout: 86400
- name: "Write Log: {{ TESTCASE }} duststorm start"
  ansible.builtin.lineinfile:
    path: "{{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}.csv"
    regexp: "^({{ ansible_hostname }},{{ SCENARIO }},{{ TESTCASE }}.*)$"
    line: "\\1,{{ lookup('pipe', 'date +%Y-%m-%dT%H:%M:%S') }}"
    backrefs: yes
- name: "Sync until Height {{ DUST_STOP_HEIGHT }} is reached"
  ansible.builtin.wait_for:
    path: "{{ ANSIBLE_LOG_CHIA_PATH }}/{{ CHIA_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.log"
    search_regex: "{{ debug_log_since_test_start }}\r(.*\r)*.*Added blocks .* to {{ DUST_STOP_HEIGHT }}.*"
    timeout: 86400
- name: "Write Log: {{ TESTCASE }} duststorm end"
  ansible.builtin.lineinfile:
    path: "{{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}.csv"
    regexp: "^({{ ansible_hostname }},{{ SCENARIO }},{{ TESTCASE }}.*)$"
    line: "\\1,{{ lookup('pipe', 'date +%Y-%m-%dT%H:%M:%S') }}"
    backrefs: yes
- name: "Stop chia processes"
  ansible.builtin.shell: |
    . {{ CHIA_SW_PATH }}/activate && chia stop all -d
- name: "Get SQLITE DB size"
  ansible.builtin.stat:
    path: "{{ BLOCKCHAIN_DB_PATH }}/{{ BLOCKCHAIN_DB_NAME }}"
    get_checksum: no
    get_mime: no
  register: sqlite_db_stats
- name: "Write Log: {{ TESTCASE }} write sqlite db size"
  ansible.builtin.lineinfile:
    path: "{{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}.csv"
    regexp: "^({{ ansible_hostname }},{{ SCENARIO }},{{ TESTCASE }}.*)$"
    line: "\\1,{{ sqlite_db_stats.stat.size }},\"{{ DESCRIPTION }}\""
    backrefs: yes
- name: "Cancel sadc data gathering and tail processes"
  become: yes
  become_user: root
  become_method: sudo
  ignore_errors: yes
  ansible.builtin.shell: |
    ps -eo pid,cmd|grep {{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.[s]a.data | sed -e 's/^[ ]*//' | cut -d" " -f1 | xargs -I {} kill -9 {}
- name: "Get device from sqlite db on"
  ansible.builtin.shell: |
    findmnt -n -o SOURCE --target {{ BLOCKCHAIN_DB_PATH }}
  register: sqlite_device
- name: "Convert and write SA output"
  ansible.builtin.shell: |
    sadf -d -T  {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data -- -m CPU | sed 's/;/,/g' > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.m.sa.csv
    sadf -d -T  {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data -- -d | sed 's/;/,/g' > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.d.sa.csv
    sadf -d -T  {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data -- -u | sed 's/;/,/g' > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.u.sa.csv
    sadf -d -T  {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data -- -S | sed 's/;/,/g' > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.S.sa.csv
    sadf -d -T  {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data -- -q | sed 's/;/,/g' > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.q.sa.csv
    sadf -d -T  {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data -- -r | sed 's/;/,/g' > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.r.sa.csv
    sadf -d -T  {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data -- -b | sed 's/;/,/g' > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.b.sa.csv
    sadf -d -T  {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data -- -n DEV | sed 's/;/,/g' > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.n.sa.csv
    sadf -g -T -O autoscale,showinfo,showidle,showtoc,skipempty {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data -- -m CPU -d -u -S -q -r -b -n DEV > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.sa.svg
- name: "Convert and write filesystem SA output if device is not ramfs or tmpfs"
  ansible.builtin.shell: |
    sadf -d -T  {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data --fs={{ sqlite_device.stdout }} -- -F | sed 's/;/,/g' > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.F.sa.csv
    sadf -g -T -O autoscale,showinfo,showidle,skipempty {{ ANSIBLE_LOG_SA_PATH }}/{{ ANSIBLE_SA_FILE_NAME }}.{{ ansible_loop.index }}.sa.data --fs={{ sqlite_device.stdout }} -- -F > {{ ANSIBLE_LOG_FILE_PATH }}/{{ ANSIBLE_LOG_FILE_NAME }}_{{ TESTCASE }}.{{ ansible_loop.index }}.F.sa.svg
  when: "sqlite_device.stdout != 'ramfs' and sqlite_device.stdout != 'tmpfs'"
